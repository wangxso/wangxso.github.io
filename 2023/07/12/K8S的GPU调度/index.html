<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> K8S的GPU调度 · 非典型程序员的一生</title><meta name="description" content="K8S的GPU调度 - wangxso"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://wangxso.github.io/atom.xml" title="非典型程序员的一生"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="非典型程序员的一生" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/xxx" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/wangxso" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">K8S的GPU调度</h1><div class="post-info">Jul 12, 2023</div><div class="post-content"><h1 id="K8S的GPU调度"><a href="#K8S的GPU调度" class="headerlink" title="K8S的GPU调度"></a>K8S的GPU调度</h1><p>环境要求: Kubernetes v1.26 [stable]</p>
<p>Kubernetes可以通过设备插件来稳定的管理你的集群不同节点之间的AMD和Nvidia的图像处理单元。</p>
<p>本章会展示用户如何使用GPU并且概述了其中的一些限制。</p>
<h2 id="使用设备插件"><a href="#使用设备插件" class="headerlink" title="使用设备插件"></a>使用设备插件</h2><p>Kubernetes 实现了设备插件，允许 Pods(Pods是K8S中可以创建和管理的最小的可部署计算单元)访问专门的硬件特性，如 GPUs。</p>
<p>首先作为管理员，你应该先给GPU装上相关公司提供的驱动程序和运行相应的设备插件程序，下面有几个主流公司的设备插件程序地址:</p>
<p>AMD: </p>
<p><a target="_blank" rel="noopener" href="https://intel.github.io/intel-device-plugins-for-kubernetes/cmd/gpu_plugin/README.html">Intel GPU device plugin for Kubernetes — Intel® Device Plugins for Kubernetes  documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/RadeonOpenCompute/k8s-device-plugin#deployment">GitHub - RadeonOpenCompute&#x2F;k8s-device-plugin: Kubernetes (k8s) device plugin to enable registration of AMD GPU to a container cluster</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/k8s-device-plugin#quick-start">GitHub - NVIDIA&#x2F;k8s-device-plugin: NVIDIA device plugin for Kubernetes</a></p>
<p>如果你安装了相应的插件，你的集群会暴露出一个可定制的调度资源比如<code>amd.com/gpu</code> 和</p>
<p><code>[nvidia.com/gpu](http://nvidia.com/gpu)</code> 。</p>
<p>通过自定义的GPU资源，你可以从容器中使用这些GPU，就像你请求CPU和内存资源的方式一样。</p>
<p>然后在如何自定义设备的制定需求的时候有一些限制。</p>
<p>GPU只能在限制下被指定，这意味着：</p>
<ul>
<li>你可以在不指定请求的情况下指定GPU的限制。因为默认情况下k8s会将这个限制作为对请求的默认限制。</li>
<li>你可以指定对请求的限制的同时也可以设置对GPU的限制，但是这两个值必须相等。</li>
<li>你不能再没有指定GPU限制的情况下也不设置请求的限制。</li>
</ul>
<p>下面是一个有关Pod请求GPU的清单示例:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-vector-add</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example-vector-add</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">&quot;registry.example/example-vector-add:v42&quot;</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">limits:</span></span><br><span class="line">          <span class="attr">gpu-vendor.example/example-gpu:</span> <span class="number">1</span> <span class="comment"># requesting 1 GPU</span></span><br></pre></td></tr></table></figure>

<h2 id="包含不同类型-GPU-的集群"><a href="#包含不同类型-GPU-的集群" class="headerlink" title="包含不同类型 GPU 的集群"></a>包含不同类型 GPU 的集群</h2><p>如果集群中的不同节点具有不同类型的 GPU，那么可以使用节点标签和节点选择器将 pods 调度到适当的节点。</p>
<p>比如:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Label your nodes with the accelerator type they have.</span></span><br><span class="line">kubectl label nodes node1 accelerator=example-gpu-x100</span><br><span class="line">kubectl label nodes node2 accelerator=other-gpu-k915</span><br></pre></td></tr></table></figure>

<p>标签键的accelerator只是一个例子; 如果愿意，可以使用不同的标签键。</p>
<h2 id="自动节点标记"><a href="#自动节点标记" class="headerlink" title="自动节点标记"></a>自动节点标记</h2><p>如果你使用的是 AMD GPU 设备，则可以部署节点标签器。节点标签器是一个控制器，自动标记你的节点中的GPU 设备属性。</p>
<hr>
<p>NVIDIA 的类似功能由 <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/gpu-feature-discovery/blob/main/README.md">GPU feature discovery</a>提供。</p>
<p>reference: <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/">https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/</a></p>
</div></article></div></main><footer><div class="paginator"><a href="/2023/07/19/V2X%E5%9C%BA%E6%99%AF%E5%8F%91%E5%B1%95%E5%92%8C%E4%BB%BF%E7%9C%9F/" class="prev">PREV</a><a href="/2023/07/11/%E5%85%B3%E4%BA%8ECarla%E4%B8%A4%E4%B8%89%E7%82%B9%E4%BA%8B/" class="next">NEXT</a></div><div class="copyright"><p>© 2019 - 2023 <a href="https://wangxso.github.io">wangxso</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"G-51FZKV3KE9",'auto');ga('send','pageview');</script></body></html>